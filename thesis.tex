%% -*- coding: utf-8; -*-

\documentclass[phd,american]{ThesisPUC}

%---------- Math ----------%
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{bbm}
%\usepackage{ulem}
%---------- Floting ----------%
\usepackage{float}
% ---------- References ----------%
%\usepackage[sort&compress,round,comma,numbers]{natbib}
%\usepackage{natbib}
\input{latex_helper}
%---------- Algorithm ----------%
\input{conf_alg}
%---------- Tables ----------%
\usepackage{multicol}
\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{tabularx}
%---------- TiKz ----------%
\usepackage{threeparttable}
\usepackage{standalone}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{psfrag,epsf}
\usepackage{multirow}
\usepackage{listings}
\usepackage{soul}
%----------citation------------%
%\usepackage{apacite}

%-----------color-----------------%
\definecolor{dkblue}{rgb}{0,0,.6}
\definecolor{turquoise}{rgb}{0.25,0.87,0.82}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{dkred}{rgb}{0.7,0,0}
\definecolor{indigo}{rgb}{0.294, 0, 0.51}
\definecolor{cyan}{rgb}{0, 0.70, 0.70}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{black}{rgb}{0,0,0}

\newcommand{\pmendes}[1]{\color{red}\textbf{paulo says: }#1\color{black}}


%\pagestyle{plain}


%Para o código em EPL
\lstdefinestyle{EPLStyle}{
  numbers=left,
  numberstyle=\footnotesize\ttfamily,
  language=SQL,
  frame=tblr,
  aboveskip=0mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{dkgreen},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3,
  %Adiciona as keywords específicas da EPL Esper
  morekeywords={after, at, context, current_timestamp,  define, distinct, every, first, grouping, grouping_id, hour, hours, initiated, inner, instanceof, irstream, is, istream, last, match_recognize,  measures, min, minute, minutes, microsecond, microseconds, millisecond, milliseconds, msec, new, offset, output, partition, pattern, rstream, sec, second, seconds, sets, some, snapshot, sql, start, terminated, then, until, usec, using, variable, weekday, when, while, window, schema},
%
  frameround=tttt,
}

\graphicspath{{images/}}

% ---------- Cover ----------%
% Adjust the advisor's title according to gender(Prof. or Prof$^{\text{a}}$.)
\author{Paulo Renato Conceição Mendes}
\authorR{Mendes, Paulo Renato Conceição}
\advisor{Sérgio Colcher}{Prof.}
\advisorR{Colcher, Sérgio}

% This thesis will use colored figures, this goes in the catalographic sheet
\usecolour{true}
\title{Localização Espaço-temporal de Atores em Vídeos/Vídeos 360 e suas Aplicações}

\titleuk{Spatio-temporal Localization of Actors in Video/360-Video and its Applications}

\day{16$^{th}$}
\month{August}
\myyear{2021}

% CDD is the registry number of the area, given by the library. Our area (informatics) is 004.
\city{Rio de Janeiro}
\CDD{004}
\department{Informática}
\program{Informática}
\school{Centro Técnico Científico}
\university{Pontifícia Universidade Católica do Rio de Janeiro}
\uni{PUC-Rio}

%---------- Jury ----------%

% Internal jury members are declared with \jurymember{name}{title}{department}{university}
% external jury members are declared with \extjurymember{name}{title}{university}
\jury{
  \jurymember{Alberto Barbosa Raposo}{Prof.}{Departamento de Informática}{PUC-Rio}
  \extjurymember{Roberto Gerson de Albuquerque Azevedo}{Dr.}{Disney Research}
}

%---------- Front letters ----------%
\resume
{
Bachelor's degree in Computer Science at Federal University of Maranhão (UFMA) in 2019.
}

\acknowledgment
{
\noindent
Thanks to my advisor Prof. Sérgio Colcher for his guidance and support in this journey.
Thanks to my family for the endless support.
Thanks to my friends from TeleMídia Lab, for their friendship and support. To all colleagues, faculty and staff of the PUC Rio Department of Informatics for the fellowship, learning and support.
This study was financed in part by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - Brasil (CAPES) - Finance Code 001.
}


% Workaround for keywords. The keywords in the catalographic sheet must be separated by dots, while the ones shown in the abstract must be separated by semi-colons.
% Thats why we have two commands for each language: \keywords declares the keywords for the catalographic sheet, while \keywordsabstract declares the ones for the abstract.
\keywords
{
  \key{Clusterização}
  \key{Reconhecimento Facial}
  \key{Recomendação de Vídeo}
  \key{Vídeo 360}
  
  
}

\keywordsabstract
{
  \key{Clusterização;}
  \key{Reconhecimento Facial;}
  \key{Recomendação de Vídeo;}
  \key{Vídeo 360.}
}

\keywordsuk
{

  \key{Clustering}
  \key{Face Recognition}
  \key{Video Recommendation}
  \key{360-Video}
}

\keywordsabstractuk
{
  \key{Clustering;}
  \key{Face Recognition;}
  \key{Video Recommendation;}
  \key{360-Video.}
}

\abstract{
 A popularidade de plataformas para o armazenamento e compartilhamento de vídeo tem criado um volume massivo de horas de vídeo. Dado um conjunto de atores presentes em um vídeo, a geração de metadados com a determinação temporal dos intervalos em que cada um desses atores está presente, bem como a localização no espaço 2D dos quadros em cada um desses intervalos pode facilitar a recuperação de vídeo e a recomendação. Neste trabalho, nós investigamos a \emph{Clusterização Facial em Vídeo} para a localização espaço-temporal de atores. Primeiro descrevemos nosso método de \emph{Clusterização Facial em Vídeo} em que utilizamos métodos de detecção facial, geração de \emph{embeddings} e clusterização para agrupar faces dos atores em diferentes quadros e fornecer a localização espaço-temporal destes atores. Então, nós exploramos, propomos, e investigamos aplicações inovadoras dessa localização espaço-temporal em três diferentes tarefas: (i) \emph{Reconhecimento Facial em Vídeo}, (ii) \emph{Recomendação de Vídeos Educacionais} e (iii) \emph{Posicionamento de Legendas em Vídeos 360°}. Para a tarefa (i), propomos um método baseado na similaridade de clústeres que é facilmente escalável e obteve um recall de 99.435\% e uma precisão de 99.131\% em um conjunto de vídeos. Para a tarefa (ii), propomos um método não supervisionado baseado na presença de professores em diferentes vídeos. Tal método não requer nenhuma informação adicional sobre os vídeo e obteve um valor mAP$\approx$99\%. Para a tarefa (iii), propomos o posicionamento dinâmico de legendas baseado na localização de atores em vídeo 360°.  
}

\abstractuk{
  
  The popularity of platforms for the storage and transmission of video content has created a substantial volume of video data. Given a set of actors present in a video, generating metadata with the temporal determination of the interval in which each actor is present, and their spatial 2D localization in each frame in these intervals can facilitate video retrieval and recommendation. In this work, we investigate \emph{Video Face Clustering} for this spatio-temporal localization of actors in videos. We first describe our method for \emph{Video Face Clustering} in which we take advantage of face detection, embeddings, and clustering methods to group similar faces of actors in different frames and provide the spatio-temporal localization of them. Then, we explore, propose, and investigate innovative applications of this spatio-temporal localization in three different tasks: (i) \emph{Video Face Recognition}, (ii) \emph{Educational Video Recommendation} and (iii) \emph{Subtitles Positioning in 360-video}. For (i), we propose a cluster-matching-based method that is easily scalable and achieved a recall of 99.435\% and precision of 99.131\% in a small video set. For (ii), we propose an unsupervised method based on the presence of lecturers in different videos that does not require any additional information from the videos and achieved a mAP$\approx$99\%. For (iii), we propose a dynamic placement of subtitles based on the automatic localization of actors in 360-video.
  
}


% WARNING
% The epigraph, if present, must come before the first chapter, always.
% There is a list of abreviations (abrevs.tex) which is included automatically in the ThesisPUC.cls, and is optional, comment the \include{abrevs} line if you do not wish to included it.
% Rationale: In the original template, the list of abreviations came before the epigraph, which caused problems with the university library, thus I've included it in the cls file.
% TODO: Declare a boolean option in the ThesisPUC.cls class in order to selectively include the abreviations list.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\input{chapters/01_Introduction}
\input{chapters/02_Related}
\input{chapters/03_video_face_clustering}
\input{chapters/04_face_recognition}
\input{chapters/05_educational_recommendation}
\input{chapters/06_automatic_subtitles}
\input{chapters/Conclusions}

\arial
\bibliography{references}

% Apendix chapters below.
%\normalfont
%\appendix
%\input{appendix.tex}

\bibliographystyle{bibstyles/IEEEtran}

\end{document}