\newpage
\chapter{Automatic Subtitles Positioning in 360-Video}
\label{chap:subtitles_positioning}

In \cite{mendes2020authoring}, we proposed an authoring model for interactive 360-video. In such a model, we can define interactive 360-videos that are presented together with additional information attached to it, such as image, text, 2D traditional videos and spatial audio. The positioning of such information is defined by their polar coordinates, start time and duration. For instance, we can define that a text moves with the user's head motion and is always visible or that such text is placed at a fixed position if its in user's the field of view. In this chapter we describe how \emph{video face clustering} can be used together with this authoring model for automatic subtitles positioning in 360-video. In Section \ref{sec:authoring_model}, we describe the authoring model we proposed. Section \ref{sec:authoring_clustering_360} describes how we adapt \emph{video face clustering} for the context of 360-videos. Finally, Section \ref{sec:authoring_discussion} describes how we use both the authoring model and \emph{video face clustering} for automatic positioning subtitles in 360-videos.

\section{An Authoring Model for Interactive 360-Videos}
\label{sec:authoring_model}

\section{Video Face Clustering in 360-Videos}
\label{sec:authoring_clustering_360}

\section{Discussion}
\label{sec:authoring_discussion}