%%% -*- coding: utf-8 -*-
\newpage

\chapter{Introduction}
\label{chap:introduction}

In recent years, the popularity of platforms for the storage and transmission of video content has stimulated the production of a massive volume of video data, establishing new habits, and leveraging new applications with innovative forms of consumption of this kind of information.
%%
Just as an indicative of this huge production (and consumption) of data, we mention that, in 2019, for example, more than one billion hours of YouTube videos were watched per day.\footnote{https://kinsta.com/blog/youtube-stats/}
%%
%%Let us define relevant people present in a video file as \textit{actors}.
%%

Generating metadata with (i) the identity information of  actors present, (ii) the temporal determination of the intervals in which each of this actors are present, and (iii) their spatial localization in each of the frames along these intervals can facilitate video indexing, retrieval, recommendation and a series of other tasks which might enhance the way people interact and consume all this video data. Besides the identification, (ii) and (iii) together are what we call \textit{Spatiotemporal Localization}. 
%%
%This dissertation intends to investigate a method for this spatiotemporal localization and a series of applications that such a method enables. 

In this dissertation, we investigate a method for the spatiotemporal localization of actors in videos. Our expected contribution is two-fold: 
\begin{enumerate}
\item we propose a core process for the spatiotemporal localization in which we take advantage of face detection, embeddings and clustering methods to group similar faces (presumably from the same actors) along the frames, and \item we further explore, propose and investigate innovative application of this localization in three different practical and important tasks: Video Face Recognition, Educational Video Recommendation, and Subtitles Positioning in 360-Video.  
\end{enumerate}

The common core of this dissertation relies on its first part, in which we describe the spatiotemporal method that we call \textit{Video Face Clustering}. We describe its process composed of: \textit{frame extraction}, \textit{face detection}, \textit{embeddings generation} and \textit{clustering}. 

Based on this Video Face Clustering method for localization, we investigate three chosen applications in which we explore novel approaches, all of them enabled by that common method of localization and its benefits. 

The first application, that of face recognition, have been attracting the attention of researchers for more than two decades. Since the deep learning boom, face detection and recognition performance have greatly improved in terms of both speed and accuracy~\cite{masi2018deep}. Nowadays, face recognition systems are used in many areas such as video surveillance and security systems, video analytics systems, smart shopping, automatic face tagging in photo collections, investigative tools that search for identities in social networks based on face images, and in thousands of other applications in our daily lives.

In our work, we propose a \textit{cluster-matching-based approach} for video face recognition where clustering is used to group faces in both the face dataset and in the target video. This method was motivated (and made possible) mainly by the characteristics of our core Face Clustering method. Its main benefit is that classes (which represent different actors) do not have to be previously known, so the effort spent with annotations is significantly reduced --- as it is done over clusters instead of single images. Consequently, face recognition becomes a task of comparing clusters from the dataset with the ones extracted from images or video sources. Therefore, our approach is easily scalable and can be used to automatically generate video metadata.

The second application, that of Educational Video Recommendation, may be considered as one of a more generic class of applications referenced as \textit{recommendation system applications}, and was motivated by a shift of paradigms that we have been observing in recent years. The traditional paradigm of classroom courses, centered on the physical presence of a teacher, has been gradually giving space to online and hybrid courses, which enables the emergence of VTEs (Virtual Teaching Environment) and MOOCs~(\textit{Massive Open Online Courses}).
%%
If, on the one hand, the abundance of educational videos can contribute to and facilitate learning, on the other hand, it also makes it challenging to discover and access some specific content of interest~\cite{dias2017approach}.
This issue is usually addressed by a proactive user search (using queries, for example), or by an automatic recommendations made by specialized systems.


In general, current video recommendation methods are heavily dependent on textual information from the video, such as labels (\textit{i.e.} keywords)~\cite{mahajan2015optimising,omisore2014personalized}, or automatically generated captions \cite{barrere2020utilizaccao} from the lecturer speech. These systems face problems such as errors introduced by manually inserted labels or by imprecise speech recognition.
%%
In this work, we propose an additional feature to enhance the recommendation of educational video content which is based on actors~(in this specific case, lecturers) presence. To do that, again we take advantage of our core face clustering method. More precisely, we detect lecturers in a video taken as a reference and perform a clustering based on the face of these lecturers in different videos. Given these clusters, we extract their \textit{centroids}, and perform another clustering step for creating a relationship between videos that share the presence of the same lecturers. Finally, we rank the recommended videos based on the amount of time the referenced lecturers were present.
A particular benefit of this approach is that it can be done without supervision, allowing for new videos to be automatically analyzed.

Our third application (Subtitles Positioning in 360-Video) was motivated by the recent popularization of omnidirectional cameras and Head-Mounted-Displays (HMDs) that increased the amount of 360-video content available \cite{mendes2020authoring}. Omnidirectional videos are spherical visual signals that allow the viewer to look around a full 360-degree view of a scene from a specific point.

Several people use subtitles when consuming audiovisual media, and these subtitles are important in contributing to the understanding of the video content \cite{brown_subtitles_2017}. There are also people who choose to consume videos muted \cite{hughes_disruptive_2019}. Additionally, the work of \cite{hayati2011effect}, as referenced in \cite{hughes_disruptive_2019}, shows that consumers are more likely to watch videos entirely if they have subtitles presented with them. In traditional 2D videos, static subtitles are commonly used and they are usually placed at a fixed position, most commonly at the bottom-center of the screen \cite{rothe_dynamic_2018}.
%%
Different from traditional 2D videos, subtitles positioning in 360-videos is challenging because it involves both temporal and spatial domains \cite{agullo2019making}, and there is no fixed ``bottom-center" of the screen \cite{brown_subtitles_2017}. Most current solutions rely on positioning subtitles either statically to the viewer or at a fixed position in the 360-degree environment %\cite{mendes2020authoring}.
%%
In this work, we adapt and apply our current solution for the spatiotemporal localisation of actors to the 360-video domain. By doing that, we intend to use this localisation for positioning subtitles close to the actors in the 360-video.

\section{Structure of this Dissertation}

The remainder of this dissertation proposal is structured as follows. 
In Chapter \ref{chap:related}, we discuss some works related to the core method of our dissertation and each of the applications we investigate.
In Chapter \ref{chap:video_face_clustering}, we define our approach for spatiotemporal localization of actors, which is our core method.
The following three chapters contain the applications in which we investigate the applicability of this method.
The first application, that of \emph{Video Face Recognition}, is described in Chapter \ref{chap:face_recognition}.
In Chapter \ref{chap:educational_recommendation}, we present our application of \emph{Educational Video Recommendation}.
Our last application, that of \emph{Subtitles Positioning in 360-video}, is described in Chapter \ref{chap:subtitles_positioning}. Finally, in Chapter \ref{chap:conclusions}, we conclude this dissertation and point to possible future work.