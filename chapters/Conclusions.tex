%% -*- coding: utf-8 -*-
\newpage

\chapter{Conclusions}
\label{chap:conclusions}

In this dissertation, we present a method for spatio-temporal localization of actors based on \emph{Video Face Clustering}. As part of this method, we also define an algorithm for finding an adequate number of clusters based on the silhouette score. We investigate to what extent this method can be used as the core to leverage and enhance some innovative applications, especially in three different practical and important tasks: \emph{Video Face Recognition}, \emph{Educational Video Recommendation}, and \emph{Subtitles Positioning in 360-Video}.

For the \emph{Video Face Recognition}, we propose a cluster-matching-based approach, derived mainly by the characteristics of our core \emph{Video Face Clustering} method, which is very scalable since the effort spent with annotations is significantly reduced --- as it is done over clusters instead of single images. This method uses \emph{Video Face Clustering} and a heuristic for cluster matching to recognize people in videos. It has achieved a recall of 99.435\% and precision of 99.131\% when considering faces extracted from a set of 13 video files. As another consequence of face clustering, our technique can be useful for creating and labeling datasets in a less time-consuming way by labeling clusters instead of individual images. One of the limitations of this application is related to the size of the video set used for the overall evaluation of our method. This is due to the difficulty of finding videos where it is possible to manually identify in each frame whether each person present is registered or not in our labeled clusters.

For the \emph{Educational Video Recommendation} task, we investigate a new feature that can be used for such recommendation: the presence of specific lecturers, which again is a direct result of the application of our core method. After performing \emph{Video Face Clustering} on each video, we extract their centroids to perform another clustering step that creates a relationship of videos that share the presence of the same lecturers. Finally, we rank the recommended videos based on the amount of time that each lecturer is present. Our method uses only the video files for performing recommendations, no other information about these videos nor the identity of the lecturers is necessary. It is worth mentioning that we do not intend to substitute other video recommendation methods, rather our application shows that, if the presence of lecturers is a relevant feature for educational video recommendation, it can be used for this purpose with a mAP value of 0.99. The main limitation of this application is that we can only recommend videos in which the lecturers are visually present. As future work, we intend to investigate a hybrid recommendation approach, that combines both textual and audiovisual information from the video to create clusters.

For the \emph{Subtitles Positioning in 360-Video} task, our main contribution is the proposal of dynamic placement of subtitles based on the automatic localization of actors. To achieve this goal, we adapted our spatio-temporal localization method to the 360-video setting and created an authoring model for interactive 360-videos. Because of the severe distortions present in equirectangular 360-videos, we used an approach based on viewports extraction for the face detection step of \emph{Video Face Clustering}. To evaluate this approach against the sole use of a traditional CNN, we created a synthetic dataset by projecting images from the FDDB benchmark to equirectangular backgrounds. Our approach, which consists of using viewports with a traditional CNN, performed better than using the traditional CNN directly to the equirectangular images. Moreover, we proposed an authoring model that allows authors to design and create interactive 360 videos. The proposed model is the result of the analysis of different scenarios of immersive 360 multimedia applications. Besides supporting subtitles positioning in 360-videos, it also supports navigation among 360-videos, additional media, etc. 

In summary, we highlight the following contributions of this dissertation:
%%
\begin{enumerate}
    \item A method for video face recognition that is easily scalable and helps in labeling images dataset;
    \item A method for educational video recommendation based on the presence of lecturers;
    \item A method for face detection in equirectangular 360-images that uses models pre-trained with traditional images;
    \item A synthetic dataset for face detection in equirectangular 360-images;
    \item An authoring model for interactive 360-videos;
    \item A player for interactive 360-videos;
    \item An approach for automatic positioning subtitles in 360-videos based on the actors' positions;
\end{enumerate}

The choice for our three proposed applications was due to observations of opportunities to apply \emph{Video Face Clustering} in different contexts. We started with \emph{Video Face Recognition} task. We observed that the use of only the \emph{Video Face Clustering} part of the method could generate the time segments that each actor is present without having to identify them. Then, we hypothesized that this particular feature could also be used to clustering actors in different videos. From this observation, we decided to investigate a method for \emph{Educational Video Recommendation} using this clustering of actors in different videos. The idea for \emph{Subtitles Positioning in 360-video} came from the authoring model we developed. We observed that we could automatically identify the actors using \emph{Video Face Clustering} so that the subtitles could follow the speakers in the 360-video. Thus, we adapted \emph{Video Face Clustering} for the 360-video setting. It is worth noticing that with this adaptation, the other two applications~(\emph{Video Face Recognition} and \emph{Educational Video Recommendation}) could also be applied to the context of 360-videos.

This work has opened lots of branches for future research. For the particular case of subtitles positioning in 360-video, there is still much to explore. It is not yet clear what is the most adequate way to place subtitles relative to the actors' positions. For instance: is it better to place them above or below the actors' faces? Should the subtitles follow the actors immediately or it would be better to have a delay with a smooth transition? A path towards answering these questions is by experimenting and evaluating these and other possible settings with users.

Other possible future work comes from the combination of the applications we explored in this dissertation. For instance, the identification of lecturers using a lecturer's image dataset with \emph{Video Face Recognition} could improve the task of \emph{Educational Video Recommendation} by inserting additional relationships among lecturers~(e.g. lecturers that teach the same subject). Another possibility is to use \emph{Video Face Recognition} to identify and insert the name of the actor present in 360-videos together with the subtitles so that the users know who is talking when the actor is not visible to them.

Although this dissertation has focused on faces, the methods and techniques here investigated could also be applied in other contexts. For instance, we could recommend videos based on the presence of the same \emph{actions} in different videos, so that a reference video with many actions related to culinary, for example, such as pouring and chopping should have videos with similar \emph{actions} as recommended. For doing that, we should be able to represent each action identified as an embedding~(vector). Then, the remainder of our method for \emph{Educational Video Recommendation} could be used. In the context of 360-videos, if we could generate art embeddings from pieces of art, we could apply the process of \emph{Video Face Clustering}~(or \emph{Video Art Clustering} in this case) to detect and determine the video segments that each piece of art is present. In this case, instead of using \emph{CNNs} trained for detecting and generating embeddings for faces, we would use them for pieces of art. By doing that, we would be able to use our authoring model to attach additional media such as text and audio to pieces of art in an interactive 360-video. This application could be useful in the context of virtual tours in museums and historical sites.


\section{Publications}

 As a result of this research, three papers have already been published at relevant multimedia conferences \cite{mendes2020cluster,mendes2020ISM, mendes2020authoring}. In \cite{mendes2020cluster}, we have evaluated video face clustering together with a cluster-matching method for video face recognition. In \cite{mendes2020ISM}, we have used video face clustering and the presence of actors in different videos as a means for recommending educational videos. In \cite{mendes2020authoring}, we have developed an authoring model and a player for interactive 360-video. 