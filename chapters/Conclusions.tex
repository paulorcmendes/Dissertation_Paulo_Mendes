%% -*- coding: utf-8 -*-
\newpage

\chapter{Conclusions}
\label{chap:conclusions}

In this dissertation, we present a method for spatiotemporal localization of actors called \emph{Video Face Clustering}. As part of this method, we also define an algorithm for finding an adequate number of clusters based on the silhouette score. We investigate in what extent this method can be used as the core to leverage and enhance some innovative applications, specially in three different  practical and important tasks: Video Face Recognition, Educational Video Recommendation, and Subtitles Positioning in 360-Video.

For the Video Face Recognition, we propose a cluster-matching-based approach, derived mainly by the characteristics of our core Face Clustering method, which is very scalable since the the effort spent with annotations is significantly reduced --- as it is done over clusters instead of single images. This method uses \emph{video face clustering} and a heuristic for cluster matching in order to recognize people in video. It has achieved a recall of 99.435\% and a precision of 99.131\% when considering faces extracted from a set of 13 video files. As another consequence of face clustering, our technique can be useful for creating and labeling datasets on a less time-consuming way by labeling clusters instead of individual images.

For the Educational Video Recommendation task, we investigate a new feature that can be used for video such recommendation: the presence of specific lecturers, which again is a direct result of the application of our core method. After performing \emph{video face clustering} on each video, we extract their centroids to perform another clustering step that creates a relationship of videos that share the presence of the same lecturers. Finally, we rank the recommended videos based on the amount of time that each lecturer is present. Our method uses only the video files for performing recommendation, no other information about these videos nor the identity of the lecturers is necessary. It is worth mentioning that we do not intend to substitute other video recommendation methods, rather our application shows that, if the presence of lecturers is a relevant feature for educational video recommendation, it can be used for this purpose with a mAP value of 0.99.

For the Subtitles Positioning in 360-Video, our main contribution is the proposal of a dynamic placement of subtitles based on the automatic localization of actors and on the current visual position of the viewer. To achieve this goal, we adapted our spatiotemporal localization method to the 360 setting and created an authoring model for interactive 360-videos. Because of the severe distortions present in equirectangular 360-videos, we used an approach based on viewports extraction for the \emph{face detection} step of \emph{video face clustering}. In order to evaluate this approach against the sole use of a traditional CNN, we created a synthetic dataset by projecting images from the FDDB benchmark to equirectangular backgrounds. Our approach, that consists in using viewports with a traditional CNN, performed better than using the traditional CNN directly to the equirectangular images. Moreover, we proposed an authoring model that allows authors to design and create
interactive 360 videos. The proposed model is the result of the analysis of different scenarios of immersive 360 multimedia applications. Besides supporting subtitles positioning in 360-videos, it also supports navigation among 360-videos, additional media, etc. For other case studies not closely related to this dissertation, please check \cite{mendes2020authoring}. Currently, the model can be easily used through text editors with an implementation integrated with the Unity Game Engine\footnote{\url{https://github.com/TeleMidia/VR360Authoring}}.

The choice for these three applications was due to observations of opportunities to apply \emph{Video Face Clustering} in different contexts. We started with Video Face Recognition. When we observed that the the use of only the \emph{Video Face Clustering} part of the method could generate the time segments that each actor is present without having to identify them, we hypothesised that this particular feature could also be used to clustering actors in different videos. From this observation, we had the idea of developing a method for \emph{Educational Video Recommendation} using this clustering of actors in different videos. The idea for \emph{Subtitles Positioning in 360-video} came from the authoring model we developed. We observed that we could automatically identify the actors using \emph{Video Face Clustering} so that the subtitles could follow the speakers in the 360-video. With that in mind, we adapted \emph{Video Face Clustering} for the 360-video setting. 

\section{Publications}

 As results of this research, three papers have already been published at relevant multimedia conferences \cite{mendes2020cluster,mendes2020ISM, mendes2020authoring}. In \cite{mendes2020cluster}, we have evaluated video face clustering together with a cluster-matching method for video face recognition. In \cite{mendes2020ISM}, we have used video face clustering and the presence of actors in different video as a mean for recommending educational videos. In \cite{mendes2020authoring}, we have developed an authoring model and a player for interactive 360-video. 